\hypertarget{classjinja2_1_1lexer_1_1Lexer}{}\doxysection{jinja2.\+lexer.\+Lexer Class Reference}
\label{classjinja2_1_1lexer_1_1Lexer}\index{jinja2.lexer.Lexer@{jinja2.lexer.Lexer}}
\doxysubsection*{Public Member Functions}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classjinja2_1_1lexer_1_1Lexer_a9cc5255588deca9b6b3b42cd6b6fcd8b}\label{classjinja2_1_1lexer_1_1Lexer_a9cc5255588deca9b6b3b42cd6b6fcd8b}} 
None {\bfseries \+\_\+\+\_\+init\+\_\+\+\_\+} (self, \char`\"{}Environment\char`\"{} environment)
\item 
\mbox{\hyperlink{classjinja2_1_1lexer_1_1TokenStream}{Token\+Stream}} \mbox{\hyperlink{classjinja2_1_1lexer_1_1Lexer_ac8fb9829073c27c06ed4e791c5e5d2fd}{tokenize}} (self, str source, t.\+Optional\mbox{[}str\mbox{]} name=None, t.\+Optional\mbox{[}str\mbox{]} filename=None, t.\+Optional\mbox{[}str\mbox{]} state=None)
\item 
t.\+Iterator\mbox{[}\mbox{\hyperlink{classjinja2_1_1lexer_1_1Token}{Token}}\mbox{]} \mbox{\hyperlink{classjinja2_1_1lexer_1_1Lexer_a2b9f848c5b74ebc7eea810277ca8a005}{wrap}} (self, t.\+Iterable\mbox{[}t.\+Tuple\mbox{[}int, str, str\mbox{]}\mbox{]} stream, t.\+Optional\mbox{[}str\mbox{]} name=None, t.\+Optional\mbox{[}str\mbox{]} filename=None)
\item 
t.\+Iterator\mbox{[}t.\+Tuple\mbox{[}int, str, str\mbox{]}\mbox{]} \mbox{\hyperlink{classjinja2_1_1lexer_1_1Lexer_ac4ce1679f9b95c265e00a0b1f183696b}{tokeniter}} (self, str source, t.\+Optional\mbox{[}str\mbox{]} name, t.\+Optional\mbox{[}str\mbox{]} filename=None, t.\+Optional\mbox{[}str\mbox{]} state=None)
\end{DoxyCompactItemize}
\doxysubsection*{Public Attributes}
\begin{DoxyCompactItemize}
\item 
\mbox{\Hypertarget{classjinja2_1_1lexer_1_1Lexer_a6e7a71e933a1daead5f140a40bd4584a}\label{classjinja2_1_1lexer_1_1Lexer_a6e7a71e933a1daead5f140a40bd4584a}} 
{\bfseries lstrip\+\_\+blocks}
\item 
\mbox{\Hypertarget{classjinja2_1_1lexer_1_1Lexer_a7d949a2c2f4d13fe5a7a6cdfa9ca82a8}\label{classjinja2_1_1lexer_1_1Lexer_a7d949a2c2f4d13fe5a7a6cdfa9ca82a8}} 
{\bfseries newline\+\_\+sequence}
\item 
\mbox{\Hypertarget{classjinja2_1_1lexer_1_1Lexer_a22b7007a2e55580df30349d9d61ec517}\label{classjinja2_1_1lexer_1_1Lexer_a22b7007a2e55580df30349d9d61ec517}} 
{\bfseries keep\+\_\+trailing\+\_\+newline}
\end{DoxyCompactItemize}


\doxysubsection{Detailed Description}
\begin{DoxyVerb}Class that implements a lexer for a given environment. Automatically
created by the environment class, usually you don't have to do that.

Note that the lexer is not automatically bound to an environment.
Multiple environments can share the same lexer.
\end{DoxyVerb}
 

\doxysubsection{Member Function Documentation}
\mbox{\Hypertarget{classjinja2_1_1lexer_1_1Lexer_ac4ce1679f9b95c265e00a0b1f183696b}\label{classjinja2_1_1lexer_1_1Lexer_ac4ce1679f9b95c265e00a0b1f183696b}} 
\index{jinja2.lexer.Lexer@{jinja2.lexer.Lexer}!tokeniter@{tokeniter}}
\index{tokeniter@{tokeniter}!jinja2.lexer.Lexer@{jinja2.lexer.Lexer}}
\doxysubsubsection{\texorpdfstring{tokeniter()}{tokeniter()}}
{\footnotesize\ttfamily  t.\+Iterator\mbox{[}t.\+Tuple\mbox{[}int, str, str\mbox{]}\mbox{]} jinja2.\+lexer.\+Lexer.\+tokeniter (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{str}]{source,  }\item[{t.\+Optional\mbox{[}str\mbox{]}}]{name,  }\item[{t.\+Optional\mbox{[}str\mbox{]} }]{filename = {\ttfamily None},  }\item[{t.\+Optional\mbox{[}str\mbox{]} }]{state = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}This method tokenizes the text and returns the tokens in a
generator. Use this method if you just want to tokenize a template.

.. versionchanged:: 3.0
    Only ``\\n``, ``\\r\\n`` and ``\\r`` are treated as line
    breaks.
\end{DoxyVerb}
 \mbox{\Hypertarget{classjinja2_1_1lexer_1_1Lexer_ac8fb9829073c27c06ed4e791c5e5d2fd}\label{classjinja2_1_1lexer_1_1Lexer_ac8fb9829073c27c06ed4e791c5e5d2fd}} 
\index{jinja2.lexer.Lexer@{jinja2.lexer.Lexer}!tokenize@{tokenize}}
\index{tokenize@{tokenize}!jinja2.lexer.Lexer@{jinja2.lexer.Lexer}}
\doxysubsubsection{\texorpdfstring{tokenize()}{tokenize()}}
{\footnotesize\ttfamily  \mbox{\hyperlink{classjinja2_1_1lexer_1_1TokenStream}{Token\+Stream}} jinja2.\+lexer.\+Lexer.\+tokenize (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{str}]{source,  }\item[{t.\+Optional\mbox{[}str\mbox{]} }]{name = {\ttfamily None},  }\item[{t.\+Optional\mbox{[}str\mbox{]} }]{filename = {\ttfamily None},  }\item[{t.\+Optional\mbox{[}str\mbox{]} }]{state = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}Calls tokeniter + tokenize and wraps it in a token stream.\end{DoxyVerb}
 \mbox{\Hypertarget{classjinja2_1_1lexer_1_1Lexer_a2b9f848c5b74ebc7eea810277ca8a005}\label{classjinja2_1_1lexer_1_1Lexer_a2b9f848c5b74ebc7eea810277ca8a005}} 
\index{jinja2.lexer.Lexer@{jinja2.lexer.Lexer}!wrap@{wrap}}
\index{wrap@{wrap}!jinja2.lexer.Lexer@{jinja2.lexer.Lexer}}
\doxysubsubsection{\texorpdfstring{wrap()}{wrap()}}
{\footnotesize\ttfamily  t.\+Iterator\mbox{[}\mbox{\hyperlink{classjinja2_1_1lexer_1_1Token}{Token}}\mbox{]} jinja2.\+lexer.\+Lexer.\+wrap (\begin{DoxyParamCaption}\item[{}]{self,  }\item[{t.\+Iterable\mbox{[}t.\+Tuple\mbox{[}int, str, str\mbox{]}\mbox{]}}]{stream,  }\item[{t.\+Optional\mbox{[}str\mbox{]} }]{name = {\ttfamily None},  }\item[{t.\+Optional\mbox{[}str\mbox{]} }]{filename = {\ttfamily None} }\end{DoxyParamCaption})}

\begin{DoxyVerb}This is called with the stream as returned by `tokenize` and wraps
every token in a :class:`Token` and converts the value.
\end{DoxyVerb}
 

The documentation for this class was generated from the following file\+:\begin{DoxyCompactItemize}
\item 
venv/lib/python3.\+10/site-\/packages/jinja2/lexer.\+py\end{DoxyCompactItemize}
